# Ollama Modellere giriş

## Küçük Modeller ile başlama

Modelleri [ollama web sayfasından](https://ollama.com/) arayabiliriz
Ne yazık ki sıralama özellikleri çok iyi değil.

Biz öğrenme amaçlı olarak çalıştığımız için bizim için [küçük modeller](https://ollama.com/search?q=small) daha anlamlı olacaktır.
Hem daha hızlı indirilir hemde hafızada çok yer tutmazlar.


Aşağıdaki modeller bu tanıma uyuyor.

- [llama3.2:1b](https://ollama.com/library/llama3.2:1b)

```bash
ollama run llama3.2:1b
```

- [phi](https://ollama.com/library/phi)

```bash
ollama run phi
```


- [deepseek-r1:1.5b](https://ollama.com/library/deepseek-r1:1.5b)

```bash
ollama run deepseek-r1:1.5b
```

- [qwen2.4 0.5b](https://ollama.com/library/qwen2.5:0.5b)


```bash
ollama run qwen2.5:0.5b
```

[qwen 2.5 blog yazısı](https://qwenlm.github.io/blog/qwen2.5-vl/)


## Model kopyalama

Bu modeli çalıştırırken uzun uzun bu ismi yazmak zor.
Bu modelin bir takma adını oluşturalım.


```bash
ollama cp deepseek-r1:1.5b ds15
```

Bu komut model ağırlık dosyalarını kopyalamaz.
Docker mantığında bir sanal yeni model manifestosu yaratır.
Ama asıl büyük dosyalar olan ağırlık dosyaları kopyalanmaz.




```bash
cd $OLLAMA_MODELS
tree
du -h
```



## Pull vs Run

- pull modeli kütükten çeker ama çalıştırmaz.
- run modeli eğer yerelde yoksa kütükten çeker arkasından çalıştırır.

## Run Parametreler

--format
--keepalive


## Show Info


/show info

- architecture        
- parameters          
- context length      
- embedding length    
- quantization        

