## Open webui

Ollama UI listesinin başında olan bu araçın özellikleri oldukça fazladır.

- Ollama/OpenAI API Entegrasyonu
- İzinler ve Kullanıcı Grupları
- Duyarlı Tasarım (Responsive Design)
- Mobil için İlerici Web Uygulaması (PWA)
- Tam Markdown ve LaTeX Desteği
- Yerel Python Fonksiyon Çağrı Aracı
- Yerel RAG Entegrasyonu
- RAG için Web Araması
- Web Tarama Yeteneği
- Görüntü Oluşturma Entegrasyonu (Yerel ComfyUI)


![open webui ekran görüntüsü](images/screenshot-open-webui.png){width=800}


[Github open webui deposu](https://github.com/open-webui/open-webui)

- backend FastAPI
- frontend svelte


### Python paket ile open-webui kurulum


Opsiyonel olarak, paket çakışmalarını engellemek için, sanal ortam (virtual environment) oluşturun.

```bash
python -m venv venv-open-webui
```

Sanal ortamı aktive edin.

Linux/Mac

```bash
source ./venv-open-webui/bin/activate
```

Windows

```bash
.\venv-open-webui\Scripts\activate.bat
```


Arkasından open-webui paketini kurun.

```bash
pip install open-webui
```

Aşağıdaki komut ile çalıştırın.

```bash
open-webui serve
```

Bu kullanımda çok fazla dosya indiriliyor ve docker kullanımından daha zor.


### Docker Open webui kullanımı


[NVDIA container toolkit](https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html) kurmam gerekti.

Kendi web sitesinde aşağıdaki komut ile çalıştırmamız tavsiye ediliyor.

```bash
docker run -d -p 3000:8080 --add-host=host.docker.internal:host-gateway -v open-webui:/app/backend/data --name open-webui --restart always ghcr.io/open-webui/open-webui:main
```

Ama ben bu komutta sorun yaşadım.



Bunun yerine aşağıdaki komut ile çalıştırabildim.


```bash
docker run --detach --gpus all --network=host -v open-webui:/app/backend/data --name open-webui  -e PORT=8081 -e WEBUI_AUTH=false ghcr.io/open-webui/open-webui:cuda 
```




Komut açıklaması

- --detach arka planda çalıştır
- --gpus all gpu kullanımına izin ver
- --network=host , çalıştığı makine ile ağ paylaşımı. 
- Bu sayede ollama'ya erişim yapabiliyoruz.
- -v volume ataması yapıyor 
- bu sayede docker stop, run yapılsa bile veriler saklanıyor.
- -e PORT=8081 çalıştığı port numarası değiştirmek için
- -e WEBUI_AUTH=false Bu argumanı vererek kullanıcı oluşturmayı engelliyorum.
Eğer bu ortam değişkeni olmazsa ilk açılışta bir kullanıcı oluşturup her seferinde bilgilerini girmeniz gerekiyor.





Eğer bilgisayarınız tekrar başladığında open webui çalışmasını istiyorsanız aşağıdaki argumanı ekleyin. 

- --restart always  




```bash
docker run --detach --network=host -v open-webui:/app/backend/data --name open-webui  -e PORT=8081 -e WEBUI_AUTH=false ghcr.io/open-webui/open-webui:cuda 
```

İlk çalıştırdığımızda, ollama bağlantısıını düzeltmemiz gerekiyor.
Sağdaki menüden settings, admin settings seçiniz.
Arkasından connections üzerinde 

- http://host.docker.internal:11434

değerini

- http://localhost:11434


yapınız.
Eğer ilk verdiğim komut ile open-webui çalıştıysa bu bağlantı değişikliğini yapmanıza gerek yoktur.


![Open webui özellikler: Bağlantılar](images/screenshot-open-webui-settings-connections.png){width=800}

Eğer bu değişikliği yaptıktan sonra hala Ollama modellerinizi göremiyorsanız.
Aşağıdaki komut ile docker container bash açınız.

```bash
docker exec -it --name open-webui bash
```

Burada aşağıdaki komutu çalıştırınız.

```bash
curl http://localhost:11434
```

sonuç olarak aşağıdaki gibi Ollama'nın çalıştığını görmeniz gerekir.

>Ollama is running

Eğer görmüyorsanız, ya Ollama'yı ollama serve ile çalıştırmayı unuttunuz yada docker localhost'a ulaşmıyor.




**Demo**

1. Giriş
2. Settings ollama json api uç noktası ekle
3. Model seçme
4. chat
5. chat rename
6. dokuman upload
7. resim ekle
8. Karşılaştırmalı chat
9. değerlendirmeleri göster




### Open webui için diğer öğreticiler

- [Is Open Webui The Ultimate Ollama Frontend Choice?](https://www.youtube.com/watch?v=16fWf0VVeIo)

- [Getting Started with Ollama and Web UI](https://www.youtube.com/watch?v=BzFafshQkWw)





